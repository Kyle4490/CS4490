import os

# import torch as torch
# import transformers as tf
# from torch.testing._internal.common_utils import args
#
# device = torch.device(args.device if torch.cuda.is_available() else "cpu")
# print(device)

# os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
# os.environ["CUDA_VISIBLE_DEVICES"] = "1"
#
# config = tf.ConfigProto()
# config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 占用GPU90%的显存
# session = tf.Session(config=config)
#
# config = tf.ConfigProto()
# config.gpu_options.allow_growth = True
# session = tf.Session(config=config)

# set to run on GPU

